{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent System with Genie + LLM Summarization\n",
        "\n",
        "This notebook creates a multi-agent system where:\n",
        "1. **Genie Agent** provides structured data (tables, statistics)\n",
        "2. **Supervisor Agent** (Llama 3.1) creates natural language summaries\n",
        "3. **Output includes BOTH** the table and the summary\n",
        "\n",
        "## Prerequisites\n",
        "- Genie Space created and configured\n",
        "- Databricks serving endpoint access\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U -qqq langgraph-supervisor==0.0.30 mlflow[databricks] databricks-langchain databricks-agents uv \n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Enhanced Multi-Agent System\n",
        "\n",
        "Key enhancement: The supervisor prompt explicitly instructs the LLM to:\n",
        "- Preserve structured data from Genie\n",
        "- Add a natural language summary\n",
        "- Provide insights and key findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile agent.py\n",
        "import json\n",
        "from typing import Generator, Literal\n",
        "from uuid import uuid4\n",
        "\n",
        "import mlflow\n",
        "from databricks_langchain import (\n",
        "    ChatDatabricks,\n",
        "    DatabricksFunctionClient,\n",
        "    UCFunctionToolkit,\n",
        "    set_uc_function_client,\n",
        ")\n",
        "from databricks_langchain.genie import GenieAgent\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain.agents import create_agent\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from langgraph_supervisor import create_supervisor\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import (\n",
        "    ResponsesAgentRequest,\n",
        "    ResponsesAgentResponse,\n",
        "    ResponsesAgentStreamEvent,\n",
        "    output_to_responses_items_stream,\n",
        "    to_chat_completions_input,\n",
        ")\n",
        "from pydantic import BaseModel\n",
        "\n",
        "client = DatabricksFunctionClient()\n",
        "set_uc_function_client(client)\n",
        "\n",
        "########################################\n",
        "# Agent Configuration Models\n",
        "########################################\n",
        "\n",
        "GENIE = \"genie\"\n",
        "\n",
        "\n",
        "class ServedSubAgent(BaseModel):\n",
        "    endpoint_name: str\n",
        "    name: str\n",
        "    task: Literal[\"agent/v1/responses\", \"agent/v1/chat\", \"agent/v2/chat\"]\n",
        "    description: str\n",
        "\n",
        "\n",
        "class Genie(BaseModel):\n",
        "    space_id: str\n",
        "    name: str\n",
        "    task: str = GENIE\n",
        "    description: str\n",
        "\n",
        "\n",
        "class InCodeSubAgent(BaseModel):\n",
        "    tools: list[str]\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "TOOLS = []\n",
        "\n",
        "\n",
        "def stringify_content(state):\n",
        "    \"\"\"Convert content to string format for processing\"\"\"\n",
        "    msgs = state[\"messages\"]\n",
        "    if isinstance(msgs[-1].content, list):\n",
        "        msgs[-1].content = json.dumps(msgs[-1].content, indent=4)\n",
        "    return {\"messages\": msgs}\n",
        "\n",
        "\n",
        "########################################\n",
        "# Create LangGraph Supervisor with Enhanced Summarization\n",
        "########################################\n",
        "\n",
        "\n",
        "def create_langgraph_supervisor(\n",
        "    llm: Runnable,\n",
        "    externally_served_agents: list[ServedSubAgent] = [],\n",
        "    in_code_agents: list[InCodeSubAgent] = [],\n",
        "):\n",
        "    agents = []\n",
        "    agent_descriptions = \"\"\n",
        "\n",
        "    # Process inline code agents\n",
        "    for agent in in_code_agents:\n",
        "        agent_descriptions += f\"- {agent.name}: {agent.description}\\n\"\n",
        "        uc_toolkit = UCFunctionToolkit(function_names=agent.tools)\n",
        "        TOOLS.extend(uc_toolkit.tools)\n",
        "        agents.append(create_agent(llm, tools=uc_toolkit.tools, name=agent.name))\n",
        "\n",
        "    # Process served endpoints and Genie Spaces\n",
        "    for agent in externally_served_agents:\n",
        "        agent_descriptions += f\"- {agent.name}: {agent.description}\\n\"\n",
        "        if isinstance(agent, Genie):\n",
        "            genie_agent = GenieAgent(\n",
        "                genie_space_id=agent.space_id,\n",
        "                genie_agent_name=agent.name,\n",
        "                description=agent.description,\n",
        "            )\n",
        "            genie_agent.name = agent.name\n",
        "            agents.append(genie_agent)\n",
        "        else:\n",
        "            model = ChatDatabricks(\n",
        "                endpoint=agent.endpoint_name, use_responses_api=\"responses\" in agent.task\n",
        "            )\n",
        "            # Disable streaming for subagents for ease of parsing\n",
        "            model._stream = lambda x: model._stream(**x, stream=False)\n",
        "            agents.append(\n",
        "                create_agent(\n",
        "                    model,\n",
        "                    tools=[],\n",
        "                    name=agent.name,\n",
        "                    post_model_hook=stringify_content,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # ENHANCED SUPERVISOR PROMPT with explicit summarization instructions\n",
        "    prompt = f\"\"\"\n",
        "You are a supervisor in a multi-agent system specialized in workforce analytics, talent mobility, and attrition analysis.\n",
        "\n",
        "Your workflow:\n",
        "1. **Understand the user's request** - What insights are they seeking?\n",
        "2. **Check chat history** - Has this been answered already?\n",
        "3. **Delegate if needed** - Route to the appropriate agent if information is missing\n",
        "4. **Analyze & Summarize** - When an agent returns data:\n",
        "   \n",
        "   **CRITICAL: You MUST provide BOTH:**\n",
        "   \n",
        "   a) **Natural Language Summary** (2-4 sentences):\n",
        "      - State the key finding that directly answers the user's question\n",
        "      - Highlight the most significant insight or trend\n",
        "      - Note any notable patterns, outliers, or anomalies\n",
        "      - Use specific numbers and percentages from the data\n",
        "      - Make it actionable and business-relevant\n",
        "   \n",
        "   b) **Preserve the structured data** - Keep tables and detailed results intact\n",
        "   \n",
        "5. **Response Format:**\n",
        "   ```\n",
        "   [Your natural language summary here - clear, insightful, specific]\n",
        "   \n",
        "   [Detailed data/table follows]\n",
        "   ```\n",
        "\n",
        "**Example Good Response:**\n",
        "\"The analysis reveals that Sales has the highest attrition rate at 15.2%, nearly double the company average of 8.1%. This is primarily driven by high turnover in the first year (23% of new Sales hires leave within 12 months). Engineering shows the strongest retention at 6.3%, suggesting successful retention programs in technical roles.\"\n",
        "\n",
        "[Table with detailed breakdown by department]\n",
        "\n",
        "Available agents:\n",
        "{agent_descriptions}\n",
        "\n",
        "Remember: Always provide actionable insights with specific data points, not just descriptions of what the data shows.\n",
        "\"\"\"\n",
        "\n",
        "    return create_supervisor(\n",
        "        agents=agents,\n",
        "        model=llm,\n",
        "        prompt=prompt,\n",
        "        add_handoff_messages=False,\n",
        "        output_mode=\"full_history\",  # Keep full history to get both summary and table\n",
        "    ).compile()\n",
        "\n",
        "\n",
        "##########################################\n",
        "# Wrap LangGraph Supervisor as a ResponsesAgent\n",
        "##########################################\n",
        "\n",
        "\n",
        "class LangGraphResponsesAgent(ResponsesAgent):\n",
        "    def __init__(self, agent: CompiledStateGraph):\n",
        "        self.agent = agent\n",
        "\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        outputs = [\n",
        "            event.item\n",
        "            for event in self.predict_stream(request)\n",
        "            if event.type == \"response.output_item.done\"\n",
        "        ]\n",
        "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
        "\n",
        "    def predict_stream(\n",
        "        self,\n",
        "        request: ResponsesAgentRequest,\n",
        "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
        "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
        "        first_message = True\n",
        "        seen_ids = set()\n",
        "\n",
        "        for _, events in self.agent.stream({\"messages\": cc_msgs}, stream_mode=[\"updates\"]):\n",
        "            new_msgs = [\n",
        "                msg\n",
        "                for v in events.values()\n",
        "                for msg in v.get(\"messages\", [])\n",
        "                if msg.id not in seen_ids\n",
        "            ]\n",
        "            if first_message:\n",
        "                seen_ids.update(msg.id for msg in new_msgs[: len(cc_msgs)])\n",
        "                new_msgs = new_msgs[len(cc_msgs) :]\n",
        "                first_message = False\n",
        "            else:\n",
        "                seen_ids.update(msg.id for msg in new_msgs)\n",
        "                node_name = tuple(events.keys())[0]\n",
        "                yield ResponsesAgentStreamEvent(\n",
        "                    type=\"response.output_item.done\",\n",
        "                    item=self.create_text_output_item(\n",
        "                        text=f\"<name>{node_name}</name>\", id=str(uuid4())\n",
        "                    ),\n",
        "                )\n",
        "            if len(new_msgs) > 0:\n",
        "                yield from output_to_responses_items_stream(new_msgs)\n",
        "\n",
        "\n",
        "#######################################################\n",
        "# Configure Foundation Model and Sub-Agents\n",
        "#######################################################\n",
        "\n",
        "# Foundation model for supervisor (will generate summaries)\n",
        "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\"\n",
        "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
        "\n",
        "# Configure your Genie Space\n",
        "EXTERNALLY_SERVED_AGENTS = [\n",
        "    Genie(\n",
        "        space_id=\"01f0c9f705201d14b364f5daf28bb639\",  # TODO: Update with your Genie Space ID\n",
        "        name=\"talent_genie\",\n",
        "        description=\"Analyzes talent stability, mobility patterns, attrition risk, and workforce trends. Provides structured data including statistics, tables, and detailed breakdowns by department, role, tenure, and other dimensions.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Optional: Add UC function-calling agents\n",
        "IN_CODE_AGENTS = []\n",
        "\n",
        "#################################################\n",
        "# Create Supervisor and Set Up MLflow\n",
        "#################################################\n",
        "\n",
        "supervisor = create_langgraph_supervisor(llm, EXTERNALLY_SERVED_AGENTS, IN_CODE_AGENTS)\n",
        "\n",
        "mlflow.langchain.autolog()\n",
        "AGENT = LangGraphResponsesAgent(supervisor)\n",
        "mlflow.models.set_model(AGENT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Agent\n",
        "\n",
        "Test the agent locally before deploying. You should see:\n",
        "1. **Summary** from the supervisor (natural language insights)\n",
        "2. **Table** from Genie (structured data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent import AGENT\n",
        "\n",
        "# Test with a question that will require Genie to query data\n",
        "input_example = {\n",
        "    \"input\": [\n",
        "        {\"role\": \"user\", \"content\": \"Which department has the highest attrition rate?\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Get the response\n",
        "response = AGENT.predict(input_example)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test streaming to see the flow\n",
        "print(\"=\" * 80)\n",
        "print(\"STREAMING OUTPUT (shows agent handoffs and responses)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for event in AGENT.predict_stream(input_example):\n",
        "    output = event.model_dump(exclude_none=True)\n",
        "    \n",
        "    # Extract and display content\n",
        "    if 'item' in output and 'content' in output['item']:\n",
        "        for content_item in output['item']['content']:\n",
        "            if 'text' in content_item:\n",
        "                text = content_item['text']\n",
        "                \n",
        "                # Highlight agent names\n",
        "                if text.startswith('<name>'):\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"âžœ Agent: {text}\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "                else:\n",
        "                    print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log the Agent to MLflow\n",
        "\n",
        "Log the agent with automatic authentication for Databricks resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from agent import EXTERNALLY_SERVED_AGENTS, LLM_ENDPOINT_NAME, TOOLS, Genie\n",
        "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
        "from mlflow.models.resources import (\n",
        "    DatabricksFunction,\n",
        "    DatabricksGenieSpace,\n",
        "    DatabricksServingEndpoint,\n",
        "    DatabricksSQLWarehouse,\n",
        "    DatabricksTable\n",
        ")\n",
        "from pkg_resources import get_distribution\n",
        "\n",
        "# Configure resources for automatic authentication\n",
        "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
        "\n",
        "# Add SQL Warehouse and tables for Genie Space\n",
        "# TODO: Update these with your actual warehouse and table names\n",
        "resources.append(DatabricksSQLWarehouse(warehouse_id=\"148ccb90800933a1\"))\n",
        "resources.append(DatabricksTable(table_name=\"akash_s_demo.talent.fact_attrition_snapshots\"))\n",
        "resources.append(DatabricksTable(table_name=\"akash_s_demo.talent.dim_employees\"))\n",
        "resources.append(DatabricksTable(table_name=\"akash_s_demo.talent.fact_compensation\"))\n",
        "resources.append(DatabricksTable(table_name=\"akash_s_demo.talent.fact_performance\"))\n",
        "resources.append(DatabricksTable(table_name=\"akash_s_demo.talent.fact_role_history\"))\n",
        "\n",
        "# Add UC function tools if any\n",
        "for tool in TOOLS:\n",
        "    if isinstance(tool, VectorSearchRetrieverTool):\n",
        "        resources.extend(tool.resources)\n",
        "    elif isinstance(tool, UnityCatalogTool):\n",
        "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
        "\n",
        "# Add Genie Space\n",
        "for agent in EXTERNALLY_SERVED_AGENTS:\n",
        "    if isinstance(agent, Genie):\n",
        "        resources.append(DatabricksGenieSpace(genie_space_id=agent.space_id))\n",
        "    else:\n",
        "        resources.append(DatabricksServingEndpoint(endpoint_name=agent.endpoint_name))\n",
        "\n",
        "# Log the model\n",
        "with mlflow.start_run():\n",
        "    logged_agent_info = mlflow.pyfunc.log_model(\n",
        "        name=\"agent\",\n",
        "        python_model=\"agent.py\",\n",
        "        resources=resources,\n",
        "        pip_requirements=[\n",
        "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
        "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
        "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
        "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
        "            f\"langgraph-supervisor=={get_distribution('langgraph-supervisor').version}\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "print(f\"âœ… Model logged successfully!\")\n",
        "print(f\"Run ID: {logged_agent_info.run_id}\")\n",
        "print(f\"Model URI: {logged_agent_info.model_uri}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register to Unity Catalog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.set_registry_uri(\"databricks-uc\")\n",
        "\n",
        "# TODO: Update these with your catalog, schema, and model name\n",
        "catalog = \"akash_s_demo\"\n",
        "schema = \"talent\"\n",
        "model_name = \"mobility_attrition_with_summary\"\n",
        "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
        "\n",
        "# Register the model\n",
        "uc_registered_model_info = mlflow.register_model(\n",
        "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
        ")\n",
        "\n",
        "print(f\"âœ… Model registered to Unity Catalog!\")\n",
        "print(f\"Model: {UC_MODEL_NAME}\")\n",
        "print(f\"Version: {uc_registered_model_info.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the Agent\n",
        "\n",
        "Deploy the agent to a serving endpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks import agents\n",
        "\n",
        "# Deploy the agent\n",
        "deployment_info = agents.deploy(\n",
        "    UC_MODEL_NAME, \n",
        "    uc_registered_model_info.version,\n",
        "    tags={\"enhanced\": \"with_summary\"},\n",
        "    deploy_feedback_model=False\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸš€ DEPLOYMENT INITIATED\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nYour agent with enhanced summarization is being deployed!\")\n",
        "print(\"\\nðŸ“Š What to expect:\")\n",
        "print(\"  â€¢ Natural language summaries from Llama 3.1\")\n",
        "print(\"  â€¢ Structured tables from Genie\")\n",
        "print(\"  â€¢ Both in a single response\")\n",
        "print(\"\\nThis deployment can take up to 15 minutes.\")\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Output\n",
        "\n",
        "When you ask: **\"Which department has the highest attrition rate?\"**\n",
        "\n",
        "You will get:\n",
        "\n",
        "### From Supervisor (Summary):\n",
        "```\n",
        "The Sales department shows the highest attrition rate at 15.2%, significantly above \n",
        "the company average of 8.1%. This elevated turnover is concentrated among employees \n",
        "with less than 2 years tenure, suggesting onboarding or early-career challenges. \n",
        "The Engineering department maintains the strongest retention at 6.3%, indicating \n",
        "effective retention strategies in technical roles.\n",
        "```\n",
        "\n",
        "### From Genie (Table):\n",
        "```\n",
        "| Department  | Attrition Rate | Employee Count | Avg Tenure |\n",
        "|-------------|----------------|----------------|------------|\n",
        "| Sales       | 15.2%          | 450            | 2.3 years  |\n",
        "| Support     | 12.8%          | 320            | 2.8 years  |\n",
        "| Marketing   | 10.5%          | 180            | 3.2 years  |\n",
        "| Operations  | 9.2%           | 280            | 3.8 years  |\n",
        "| Engineering | 6.3%           | 520            | 4.5 years  |\n",
        "```\n",
        "\n",
        "## Key Improvements\n",
        "\n",
        "âœ… **Natural Language Insights** - Easy to understand summaries  \n",
        "âœ… **Structured Data** - Detailed tables for analysis  \n",
        "âœ… **Actionable** - Specific numbers and trends  \n",
        "âœ… **Context-Aware** - Supervisor analyzes the data intelligently\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
